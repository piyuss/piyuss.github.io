<!DOCTYPE html>
<html lang="en">
    
    <head>
        <title>Piyush Pandey</title>
        <meta charset="utf-8">
        <meta name="description" content="This is Piyush pandey's academic portfolio. Fields of interest: Engineering, Agricultural robotics, Computer Vision, NCSU, PHD">
        <meta name="author" content="Anugya Sharma">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="refresh" content="600">
        <meta name="keywords" content="Piyush Pandey">        
        <link rel="stylesheet" type="text/css" href="./stylesheets/style.css">  
        <link rel="icon" type="img/x-icon" href="/img/fir.png">        
    </head>

    <body>
        <img class= "cursive" src="img/cursive-text.png">     

        <central>
        </central>
        

        
        <header>             
            <nav>
                <ul class="navigation">
                    <li><a href="index.html" style= "background-color:#86c7af; border-radius:5px; color:#f2ebe8; ">HOME</a></li>                    
                    <!-- <li><a href="resume.html">CV</a></li> -->
                    <li><a href="publications.html">PUBLICATIONS</a></li>
                    <li><a href="presentations.html">PRESENTATIONS</a></li>                    
                </ul>
            </nav>
        </header>

        <!-- main content /white paper -->
        <main>
            <h1>About me</h1>
            <p>Hello. I am an ORISE postdoctoral fellow at USDA-ARS working on plant phenotyping using deep learning methods.
                
                I completed my dual PhD in Engineering and Forestry at North Carolina State University. 
            </p>

            <p> I have worked on projects in high-throughput phenotyping of plants using digital images and 
                in robotic systems for forestry applications. Some of the projects are visualized
                in the slideshow below. Please use the links to publications and presentations on the navigation bar for
                 a more complete view of my work.
            </p>
            <p> I have worked on projects in high-throughput phenotyping of plants using digital images and 
                in robotic systems for forestry applications. Some of the projects are visualized
                in the slideshow below. Please use the links to publications and presentations on the navigation bar for
                 a more complete view of my work.
            </p>
        </main>
        

        <photoArea>
            <img src="img/bio-photo.png">
            <h1>Piyush Pandey</h1>

            <mediaLinks>                
                <a href="mailto:piyush.pandey@usda.gov" target="_blank"><img src="img/email-icon.png"></a>
                <a href="https://www.linkedin.com/in/piyush-pandey11" target="_blank"><img src="img/linkedin-icon.png"></a>
                <!-- https://www.linkedin.com/in/piyush-pandey11 -->
                <a href="https://github.com/piyuss" target="_blank"><img src="img/github-icon.png"></a>
                <a href="https://twitter.com/PiyushPandey__" target="_blank"><img src="img/twitter-icon.png"></a>
                <a href="https://scholar.google.fr/citations?user=O1qUwKcAAAAJ&hl" target="_blank"><img src="img/googlescholar-icon.png"></a>
            </mediaLinks>
        </photoArea>
        <!-- 1 -->
        <projectArea>
            <ProjectRowContainer>
                <h1>Synthetic Data:</h1>
                <projectRow>
                    <projectRowItem1>
                        <img width="354"  src="img/synthentic_img.png"> 
                    </projectRowItem1>
                    <projectRowItem2>
                        <p>
                            The detection of individual plants within field images is critical for many applications in precision agriculture and research. Computer vision models for object detection, while often highly accurate, require large amounts of labeled data for training, something that is not readily available for most plants. To address the challenge of creating large datasets with accurate labels, we used indoor images of maize plants to create synthetic field images with automatically derived bounding box labels, enabling the generation of thousands of synthetic images without any manual labeling. Training an object detection model (Faster R-CNN) exclusively on synthetic images led to a mean average precision (mAP) value of 0.533 when the model was evaluated on pre-processed real plot images. When fine-tuned with a small number of real plot images, the model pre-trained on the synthetic images (mAP=0.884) outperformed the model that was not pre-trained.
                        </p>
                    </projectRowItem2>
                </projectRow>
                <hr>
            </ProjectRowContainer>
        </projectArea>
        <!-- 2 -->
        <projectArea>
            <ProjectRowContainer>
                <h1>Synthetic Data:</h1>
                <projectRow>
                    <projectRowItem1>
                        <img width="354"  src="img/synthentic_img.png"> 
                    </projectRowItem1>
                    <projectRowItem2>
                        <p>
                            The detection of individual plants within field images is critical for many applications in precision agriculture and research. Computer vision models for object detection, while often highly accurate, require large amounts of labeled data for training, something that is not readily available for most plants. To address the challenge of creating large datasets with accurate labels, we used indoor images of maize plants to create synthetic field images with automatically derived bounding box labels, enabling the generation of thousands of synthetic images without any manual labeling. Training an object detection model (Faster R-CNN) exclusively on synthetic images led to a mean average precision (mAP) value of 0.533 when the model was evaluated on pre-processed real plot images. When fine-tuned with a small number of real plot images, the model pre-trained on the synthetic images (mAP=0.884) outperformed the model that was not pre-trained.
                        </p>
                    </projectRowItem2>
                </projectRow>
                <hr>
            </ProjectRowContainer>
        </projectArea>
        
        <projectArea>
            <!-- 1 -->
            <ProjectRowContainer>
                <h1>Synthetic Data:</h1>
                <projectRow>
                    <projectRowItem1>
                        <img width="354"  src="img/synthentic_img.png"> 
                    </projectRowItem1>
                    <projectRowItem2>
                        <p>
                            The detection of individual plants within field images is critical for many applications in precision agriculture and research. Computer vision models for object detection, while often highly accurate, require large amounts of labeled data for training, something that is not readily available for most plants. To address the challenge of creating large datasets with accurate labels, we used indoor images of maize plants to create synthetic field images with automatically derived bounding box labels, enabling the generation of thousands of synthetic images without any manual labeling. Training an object detection model (Faster R-CNN) exclusively on synthetic images led to a mean average precision (mAP) value of 0.533 when the model was evaluated on pre-processed real plot images. When fine-tuned with a small number of real plot images, the model pre-trained on the synthetic images (mAP=0.884) outperformed the model that was not pre-trained.
                        </p>
                    </projectRowItem2>
                </projectRow>
                <hr>
            </ProjectRowContainer>
            <!-- 2 -->
            <ProjectRowContainer>
                <h1>Synthetic Data:</h1>
                <projectRow>
                    <projectRowItem1>
                        <img width="354"  src="img/synthentic_img.png"> 
                    </projectRowItem1>
                    <projectRowItem2>
                        <p>
                            The detection of individual plants within field images is critical for many applications in precision agriculture and research. Computer vision models for object detection, while often highly accurate, require large amounts of labeled data for training, something that is not readily available for most plants. To address the challenge of creating large datasets with accurate labels, we used indoor images of maize plants to create synthetic field images with automatically derived bounding box labels, enabling the generation of thousands of synthetic images without any manual labeling. Training an object detection model (Faster R-CNN) exclusively on synthetic images led to a mean average precision (mAP) value of 0.533 when the model was evaluated on pre-processed real plot images. When fine-tuned with a small number of real plot images, the model pre-trained on the synthetic images (mAP=0.884) outperformed the model that was not pre-trained.
                        </p>
                    </projectRowItem2>
                </projectRow>
                <hr>
            </ProjectRowContainer>
            <!-- 3 -->
            <ProjectRowContainer>
                <h1>Synthetic Data:</h1>
                <projectRow>
                    <projectRowItem1>
                        <img width="354"  src="img/synthentic_img.png"> 
                    </projectRowItem1>
                    <projectRowItem2>
                        <p>
                            The detection of individual plants within field images is critical for many applications in precision agriculture and research. Computer vision models for object detection, while often highly accurate, require large amounts of labeled data for training, something that is not readily available for most plants. To address the challenge of creating large datasets with accurate labels, we used indoor images of maize plants to create synthetic field images with automatically derived bounding box labels, enabling the generation of thousands of synthetic images without any manual labeling. Training an object detection model (Faster R-CNN) exclusively on synthetic images led to a mean average precision (mAP) value of 0.533 when the model was evaluated on pre-processed real plot images. When fine-tuned with a small number of real plot images, the model pre-trained on the synthetic images (mAP=0.884) outperformed the model that was not pre-trained.
                        </p>
                    </projectRowItem2>
                </projectRow>
                <hr>
            </ProjectRowContainer>
        </projectArea>


       
        <footer> <p>© 2023 Piyush Pandey</p> </footer>
        <!-- <script src="script/script1_carousel.js"></script> -->
    </body>

</html>